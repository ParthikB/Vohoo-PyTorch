{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cats and dogs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParthikB/Vohoo-PyTorch/blob/master/cats_and_dogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3Yn5L2xfQgv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "0b72da6b-8068-468f-9c93-d514ea6b276b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-3t8VosKnEm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "373f03af-a43f-492c-c752-d5c8754f79b1"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda:0')\n",
        "  running = 'GPU'\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "  running = 'CPU'\n",
        "print(f'Running on : {running}')"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on : GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I07yCeyjyQ-J",
        "colab_type": "text"
      },
      "source": [
        "# PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRuUKjerd1db",
        "colab_type": "code",
        "outputId": "36e00c84-7be3-416a-b7b7-88c87624b299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "                                  # VARIABLES #\n",
        "DATA_EXTRACTED = True\n",
        "DATA_CREATED   = True\n",
        "DATA_BALANCED  = True\n",
        "CLIP           = 1680  #Clip every feature lenght at CLIP is data is not balanced.\n",
        "#____________________________________________________________________________________#\n",
        "                              \n",
        "                              # DOWNLOADING DATA #\n",
        "PATH = '/content/drive/My Drive/Colab Notebooks/pyTorch/data/'\n",
        "os.chdir(PATH)\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = \"parthikb\" # username from the json file \n",
        "os.environ['KAGGLE_KEY'] = \"079b1e8e73bd390b39218acc15c82b09\" # key from the json file\n",
        "!kaggle datasets download -d chetankv/dogs-cats-images\n",
        "#____________________________________________________________________________________#\n",
        "                             \n",
        "                              # EXTRACTING DATA #\n",
        "if not DATA_EXTRACTED:\n",
        "  from zipfile import ZipFile\n",
        "\n",
        "  file_name = 'dogs-cats-images.zip'\n",
        "\n",
        "  with ZipFile(file_name, 'r') as zip:\n",
        "    print('Initiating Extraction...')\n",
        "    zip.extractall()\n",
        "    print('Done!')\n",
        "#____________________________________________________________________________________#\n",
        "                               \n",
        "                                # MOVING DATA #\n",
        "# PATH += 'dog vs cat/dataset'\n",
        "# os.chdir(PATH)\n",
        "\n",
        "# To move the dataset folders...\n",
        "\n",
        "# import shutil\n",
        "# shutil.move(PATH+'/training_set', '/content/drive/My Drive/Colab Notebooks/pyTorch/data/dog vs cat/')\n",
        "# shutil.move(PATH+'/test_set', '/content/drive/My Drive/Colab Notebooks/pyTorch/data/dog vs cat/')\n",
        "#____________________________________________________________________________________#\n",
        "                          \n",
        "                           # CREATING TRAINING SET #\n",
        "PATH = '/content/drive/My Drive/Colab Notebooks/pyTorch/data/dog vs cat/training_set'\n",
        "os.chdir(PATH)\n",
        "\n",
        "class DogsVSCats:\n",
        "  IMG_SIZE     = 50\n",
        "  CATS         = os.path.join(PATH, 'cats') \n",
        "  DOGS         = os.path.join(PATH, 'dogs')\n",
        "  labels       = {CATS:0, DOGS:1}\n",
        "  training_data = []\n",
        "  cat_count, dog_count = 0, 0\n",
        "\n",
        "  def createTrainingData(self):\n",
        "    try:\n",
        "      for label in self.labels:\n",
        "        os.chdir(label)\n",
        "        data = os.listdir()\n",
        "        for image in tqdm(data):\n",
        "          img = os.path.join(label, image)\n",
        "          img = cv2.imread(img, 0)\n",
        "\n",
        "          one_hot = np.eye(len(self.labels))[self.labels[label]]\n",
        "          img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "          \n",
        "          self.training_data.append([np.array(img), one_hot])\n",
        "          \n",
        "          if label == self.CATS:\n",
        "            self.cat_count += 1\n",
        "          else:\n",
        "            self.dog_count += 1\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "\n",
        "    np.random.shuffle(self.training_data)\n",
        "    np.save('/content/drive/My Drive/Colab Notebooks/pyTorch/data/dog vs cat/training_data.npy', self.training_data)\n",
        "    print('Cats : ', self.cat_count)\n",
        "    print('Dogs : ', self.dog_count)\n",
        "    \n",
        "if not DATA_CREATED:\n",
        "  print('Creating Training set...')\n",
        "  dogsVScats = DogsVSCats()\n",
        "  dogsVScats.createTrainingData()\n",
        "\n",
        "#____________________________________________________________________________________#\n",
        "                              \n",
        "                              # BALANCING TRAINING SET #\n",
        "def balance_training_data(training_data):  \n",
        "  print('Balancing Training set...')\n",
        "  cat_counter, dog_counter = 0, 0\n",
        "  balanced_training_data = []\n",
        "\n",
        "  for data in tqdm(training_data):\n",
        "    if data[1][0] == 1 and cat_counter < CLIP: #if cat\n",
        "      cat_counter += 1\n",
        "      balanced_training_data.append(data)\n",
        "    elif data[1][1] == 1 and dog_counter < CLIP: #if dog\n",
        "      dog_counter += 1\n",
        "      balanced_training_data.append(data)\n",
        "\n",
        "  return balanced_training_data"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dogs-cats-images.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8X6_o-3XpIn",
        "colab_type": "text"
      },
      "source": [
        "# Creating Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv5wy_j91Ca3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFvtKsAA9b-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    '''\n",
        "    Network Structure:\n",
        "\n",
        "    input > \n",
        "    (1)Conv2D > (2)MaxPool2D > \n",
        "    (3)Conv2D > (4)MaxPool2D > \n",
        "    (5)Conv2D > (6)MaxPool2D > \n",
        "    (7)Linear > (8)LinearOut\n",
        "\n",
        "    '''\n",
        "\n",
        "    # Creating the convulutional Layers\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5)\n",
        "\n",
        "    self.flatten = None\n",
        "    # Creating a Random dummy sample to get the Flattened Dimensions\n",
        "    x = torch.randn(50, 50).view(-1, 1, 50, 50)\n",
        "    x = self.convs(x)\n",
        "\n",
        "    # x = torch.flatten(x)\n",
        "    # print(x.shape)\n",
        "\n",
        "    # Creating the Linear Layers\n",
        "    self.fc1   = nn.Linear(self.flatten, 512)\n",
        "    self.fc2   = nn.Linear(512, 2)\n",
        "\n",
        "    # x = self.forward(x)\n",
        "\n",
        "  def convs(self, x):\n",
        "\n",
        "    # Creating the MaxPooling Layers\n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)), kernel_size=(2, 2))\n",
        "    x = F.max_pool2d(F.relu(self.conv2(x)), kernel_size=(2, 2))\n",
        "    x = F.max_pool2d(F.relu(self.conv3(x)), kernel_size=(2, 2))\n",
        "\n",
        "    if not self.flatten:\n",
        "      self.flatten = x[0].shape[0] * x[0].shape[1] * x[0].shape[2]\n",
        "    return x\n",
        "\n",
        "  # FORWARD PASS\n",
        "  def forward(self, x):\n",
        "    x = self.convs(x)\n",
        "    x = x.view(-1, self.flatten)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.softmax(self.fc2(x), dim=1)\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xl2L6hb4YgKq",
        "colab_type": "text"
      },
      "source": [
        "# Modifying Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN9PB6_jYuDY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "56a13122-f260-4b30-b870-de8e2ba024fc"
      },
      "source": [
        "# Test split percentage\n",
        "TEST_PERCENTAGE = 0.2\n",
        "\n",
        "training_data = np.load('/content/drive/My Drive/Colab Notebooks/pyTorch/data/dog vs cat/training_data.npy', allow_pickle=True)\n",
        "training_data = balance_training_data(training_data)\n",
        "\n",
        "x = torch.tensor([data[0] for data in training_data]).view(-1, 50, 50)\n",
        "x = x/255.0\n",
        "y = torch.tensor([data[1] for data in training_data])\n",
        "\n",
        "test_size = int(x.shape[0] * TEST_PERCENTAGE)\n",
        "\n",
        "x_train, y_train = x[:-test_size], y[:-test_size]\n",
        "x_test,  y_test  = x[-test_size:].to(device), y[-test_size:].to(device)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5680/5680 [00:00<00:00, 464579.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Balancing Training set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUgDxYmpPPfk",
        "colab_type": "text"
      },
      "source": [
        "# Running Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lbzh_9SiXxaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVZzPJKSX4CD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net, EPOCHS=5, LEARNING_RATE=0.001, BATCH_SIZE=32):\n",
        "\n",
        "  optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
        "  loss_func = nn.MSELoss()\n",
        "  loss_log  = []\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    for i in tqdm(range(0, len(x_train), BATCH_SIZE)):\n",
        "        x_batch = x_train[i:i+BATCH_SIZE].view(-1, 1, 50, 50).to(device)\n",
        "        y_batch = y_train[i:i+BATCH_SIZE].to(device)\n",
        "\n",
        "        net.zero_grad()\n",
        "        output = net(x_batch)\n",
        "        loss = loss_func(output, y_batch.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    loss_log.append(loss)\n",
        "    # print(f\"Epoch : {epoch} || Loss : {loss}\")\n",
        "\n",
        "  return loss_log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_rXkXjgfl_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.plot(loss_log)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDEjcWZ8hJD7",
        "colab_type": "text"
      },
      "source": [
        "## Test Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLMrEQe4hNWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(net):\n",
        "  correct = 0\n",
        "  total   = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i in tqdm(range(len(x_test))):\n",
        "      real_class = torch.argmax(y_test[i])\n",
        "      pred_class = torch.argmax(net(x_test[i].view(-1, 1, 50, 50)))\n",
        "\n",
        "      total += 1\n",
        "      if real_class == pred_class:\n",
        "        correct += 1\n",
        "\n",
        "  accuracy = (correct/total)*100\n",
        "  print()\n",
        "  print(f'Accuracy : {round(accuracy, 2)} %')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQYPkIfyMH4A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "41568694-28f8-4f2c-9643-9bd8753171f6"
      },
      "source": [
        "net = Net().to(device)\n",
        "\n",
        "loss_log = train(net, EPOCHS=3, BATCH_SIZE=16)\n"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 168/168 [00:01<00:00, 117.49it/s]\n",
            "100%|██████████| 168/168 [00:01<00:00, 127.70it/s]\n",
            "100%|██████████| 168/168 [00:01<00:00, 126.55it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-Ti8NU4MVZM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "bb0b61cb-a8e3-479b-a000-2d753f3c9351"
      },
      "source": [
        "plt.plot(loss_log)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa8c577cc18>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEDCAYAAAAcI05xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni4gE3P8He4wASxDBfhsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3uDS35NNijg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "1d30608d-f020-4d4e-f372-418a0d869071"
      },
      "source": [
        "test(net)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 672/672 [00:00<00:00, 849.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy : 100.0 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PPNj-OUOVl_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0f8baf35-16ab-45b6-d38d-46606582dd54"
      },
      "source": [
        "loss_log"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(8.5319e-22, device='cuda:0', grad_fn=<MseLossBackward>),\n",
              " tensor(0., device='cuda:0', grad_fn=<MseLossBackward>),\n",
              " tensor(0., device='cuda:0', grad_fn=<MseLossBackward>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwOu-5WcPJX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}